{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ci_QOfvl-nur"
      },
      "source": [
        "**CREATE THE CONVOLUTION FUNTION**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xz78eAwDAwVA"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XjEH5ahC-jU0"
      },
      "outputs": [],
      "source": [
        "class CNN ():\n",
        "  def __init__(self,s_i,n_s,s_k,stride=1):\n",
        "    super().__init__()\n",
        "    self.s_o = s_i[-1]- s_k+1\n",
        "    self.stride = stride\n",
        "    self.s_k = s_k\n",
        "    self.n_k = n_s\n",
        "    self.kernels = np.random.randn(n_s,s_i[0],s_k,s_k).astype(np.float32)/ n_s\n",
        "    self.bias = np.random.randn(n_s).astype(np.float32) / n_s\n",
        "  def image_segmentation(self,x):\n",
        "    for i in range(0,self.s_o, self.stride):\n",
        "      for j in range(0,self.s_o, self.stride):\n",
        "        yield x[:,i:i+self.s_k,j:j+self.s_k],i,j\n",
        "  def forward(self,x):\n",
        "\n",
        "    conv = np.zeros(shape=(self.kernels.shape[0],self.s_o,self.s_o))\n",
        "    for k,kernel in enumerate(self.kernels):\n",
        "      for segment,i,j in self.image_segmentation(x):\n",
        "        conv[k,i,j] = self.bias[k] + np.sum(segment*kernel)\n",
        "    return conv\n",
        "  def backward(self,x,dL_dc,lr):\n",
        "    dL_Conv = np.zeros_like(self.kernels)\n",
        "    dL_in_c = np.zeros_like(x)\n",
        "    dL_bias = np.zeros_like(self.bias)\n",
        "    for segment,i,j in self.image_segmentation(x):\n",
        "      for k in range(0,self.s_k,1):\n",
        "        dL_Conv[k] +=  segment * dL_dc[k,i,j]\n",
        "        dL_in_c[:,i:i+ self.s_k,j:j+self.s_k] += self.kernels[k] * dL_dc[k,i,j]\n",
        "        dL_bias[k] += dL_dc[k,i,j]\n",
        "    self.bias -= lr* dL_bias\n",
        "    self.kernels -= lr * dL_Conv\n",
        "    return dL_in_c"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CNNp = CNN((3,5,5), 6, 2)"
      ],
      "metadata": {
        "id": "zFPsrla8YfdG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CNNp.backward(np.random.randn(3,5,5),np.random.randn(6,4,4), 0.5).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhjWz8fpYv7x",
        "outputId": "bee43abf-80b2-48b5-b591-c55423768a9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 5, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsTl7PhzZpk8"
      },
      "source": [
        "# Definition of Maxpooling Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tOJUQGnfLfyb"
      },
      "outputs": [],
      "source": [
        "class MaxPooling():\n",
        "  def __init__(self,s_i,k_s):\n",
        "    self.k_s = k_s\n",
        "    self.s_i = s_i\n",
        "    self.s_o = s_i//2\n",
        "  def segment(self,x):\n",
        "    for i in range(0,self.s_i-self.k_s+1, self.k_s):\n",
        "      for j in range(0,self.s_i-self.k_s+1, self.k_s):\n",
        "        yield x[:,i:i+self.k_s,j:j+self.k_s], i, j\n",
        "  def forward(self,x):\n",
        "    pooled = np.zeros(shape =(x.shape[0],self.s_o,self.s_o))\n",
        "    for ims,i,j in self.segment(x):\n",
        "        for s in range(0,x.shape[0]):\n",
        "            pooled[s,i//2,j//2] = np.max(ims[s])\n",
        "    return pooled\n",
        "  def backward(self,x,x_c,dL_dm):\n",
        "    dM = np.zeros_like(x_c)\n",
        "    for ims,i,j in self.segment(x_c):\n",
        "      for s in range(0,x_c.shape[0]):\n",
        "        max_value  = np.max(ims[s])\n",
        "        max_positions = np.where(ims[s] == max_value)\n",
        "        for i1, j1 in zip(max_positions[0], max_positions[1]):\n",
        "          dM[s,i+i1,j+j1] = dL_dm[s,i//2,j//2]\n",
        "    return dM"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Normal layer**"
      ],
      "metadata": {
        "id": "Zm0x49pKdQE2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6DrVR_cnJeqb"
      },
      "outputs": [],
      "source": [
        "class Linear():\n",
        "   def __init__(self,input_n,output_n):\n",
        "     self.bias = np.random.randn(1,output_n).astype(np.float32) / input_n\n",
        "     self.weighs = np.random.randn(input_n,output_n).astype(np.float32) / input_n\n",
        "\n",
        "   def Sigmoid(self,x):\n",
        "       return 1 / ( 1 + np.exp(-x))\n",
        "   def DSigmoid(self,x):\n",
        "       x = self.Sigmoid(x)\n",
        "       return x *( 1 - x)\n",
        "   def forward(self, x ):\n",
        "       return np.dot(x,self.weighs) + self.bias\n",
        "   def backward(self,x, dL, lr):\n",
        "       d_w = np.dot(x.T,dL)\n",
        "       d_b = 1 * dL\n",
        "       d_x = np.dot(dL,self.weighs.T)\n",
        "       self.weighs -= lr * d_w\n",
        "       self.bias -= lr * d_b\n",
        "\n",
        "       return d_x.reshape(x.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Classification Funtion**"
      ],
      "metadata": {
        "id": "wTCTcE2GdWY0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NoO-HM-rNrXR"
      },
      "outputs": [],
      "source": [
        "class Softmax():\n",
        "    def __init__(self):\n",
        "        self.b_layer = None\n",
        "    def forward(self,x):\n",
        "      exp = np.exp(x - np.max(x,axis = 1,keepdims = True))\n",
        "      return np.exp(x) / np.sum(np.exp(x),axis = 1,keepdims = True)\n",
        "\n",
        "    def backward(self,DL):\n",
        "        for i,gradient in enumerate(DL):\n",
        "            if gradient == 0:\n",
        "                continue\n",
        "            t_e = np.exp(self.b_layer[:])\n",
        "            S = np.sum(t_e, axis=1)\n",
        "            dL_s = - t_e[:,i] * t_e / (S**2)\n",
        "            dL_s[:,i] = t_e[:,i] * (S - t_e[:,i])/ (S**2)\n",
        "            return dL_s * gradient\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Architecture definition**"
      ],
      "metadata": {
        "id": "zo2iHlCDdcc2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kyf_a1TL9IMm"
      },
      "outputs": [],
      "source": [
        "class Net():\n",
        "    def __init__(self,n_classes,lr):\n",
        "        self.n_classes = n_classes\n",
        "        self.lr = lr\n",
        "        self.Conv1 = CNN((1,28,28),3,2)\n",
        "        self.MaxPooling1 = MaxPooling(27,2)\n",
        "\n",
        "        self.Conv2 = CNN((3,13,13),6,2)\n",
        "        self.MaxPooling2 = MaxPooling(12,2)\n",
        "\n",
        "        self.before_flatting_shape = None\n",
        "        self.Linear1 = Linear(6*6**2,5)\n",
        "        self.Linear2 = Linear(5,n_classes)\n",
        "        self.Softmax = Softmax()\n",
        "    def forward(self,x):\n",
        "        self.conv_p = [x]\n",
        "        self.max_p = []\n",
        "        x = self.Conv1.forward(x)\n",
        "        self.conv_p.append(x)\n",
        "        x = self.MaxPooling1.forward(x)\n",
        "        self.max_p.append(x)\n",
        "        x = self.Conv2.forward(x)\n",
        "        self.conv_p.append(x)\n",
        "        x = self.MaxPooling2.forward(x)\n",
        "        self.max_p.append(x)\n",
        "\n",
        "        self.before_flatting_shape = x.shape\n",
        "        x = x.flatten()\n",
        "        self.linear_p = [x[np.newaxis,:]]\n",
        "        x = self.Linear1.forward(x)\n",
        "        self.linear_p.append(x)\n",
        "        x = self.Linear1.Sigmoid(x)\n",
        "        self.linear_p.append(x)\n",
        "        x = self.Linear2.forward(x)\n",
        "        self.Softmax.b_layer = x\n",
        "        x = self.Softmax.forward(x)\n",
        "        return x\n",
        "    def backward(self,x,y):\n",
        "        y_pred = self.forward(x)\n",
        "\n",
        "        LOSS = -np.log(np.take(y_pred,y))\n",
        "\n",
        "\n",
        "        dL = np.zeros(self.n_classes)\n",
        "        dL[y] =  -1/np.take(y_pred,y)\n",
        "        dL_dout = self.Softmax.backward(dL)\n",
        "        dL_linear2 = self.Linear2.backward(self.linear_p[-1], dL_dout ,self.lr)\n",
        "        dL_sigmoid = self.Linear1.DSigmoid(self.linear_p[-2])* dL_linear2\n",
        "        dL_linear1 = self.Linear1.backward(self.linear_p[-3],dL_sigmoid,self.lr)\n",
        "        dL_linear1 = dL_linear1.reshape(self.before_flatting_shape)\n",
        "\n",
        "        dL_Maxpool2 = self.MaxPooling2.backward(self.max_p[-1],self.conv_p[-1],dL_linear1)\n",
        "        dL_Conv2 = self.Conv2.backward(self.max_p[-2], dL_Maxpool2 , self.lr)\n",
        "\n",
        "        dL_Maxpool1 = self.MaxPooling1.backward(self.max_p[-2],self.conv_p[-2],dL_Conv2)\n",
        "        dL_Conv1 = self.Conv1.backward(self.conv_p[0], dL_Maxpool1 , self.lr)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19uXn41wf1_H"
      },
      "source": [
        "**LOAD DATASET**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7YueXL2bg524"
      },
      "outputs": [],
      "source": [
        "! pip install -q kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fa4lzauGhDrw",
        "outputId": "5ffdcb14-9559-4268-bbe4-836f19e55e92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot create regular file '/root/.kaggle/': Not a directory\n"
          ]
        }
      ],
      "source": [
        "! cp kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sL4hFezkf1vC",
        "outputId": "2c323f33-4cbe-4425-9daa-c66e9555edf7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/hojjatk/mnist-dataset\n",
            "License(s): copyright-authors\n",
            "Downloading mnist-dataset.zip to /content\n",
            " 91% 20.0M/22.0M [00:00<00:00, 106MB/s] \n",
            "100% 22.0M/22.0M [00:00<00:00, 106MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d hojjatk/mnist-dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2-oi_hEpLCZ",
        "outputId": "7d0fe89c-62c8-42de-e05e-ba8b35a40256"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  mnist-dataset.zip\n",
            "  inflating: t10k-images-idx3-ubyte/t10k-images-idx3-ubyte  \n",
            "  inflating: t10k-images.idx3-ubyte  \n",
            "  inflating: t10k-labels-idx1-ubyte/t10k-labels-idx1-ubyte  \n",
            "  inflating: t10k-labels.idx1-ubyte  \n",
            "  inflating: train-images-idx3-ubyte/train-images-idx3-ubyte  \n",
            "  inflating: train-images.idx3-ubyte  \n",
            "  inflating: train-labels-idx1-ubyte/train-labels-idx1-ubyte  \n",
            "  inflating: train-labels.idx1-ubyte  \n"
          ]
        }
      ],
      "source": [
        "!unzip mnist-dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3R0crLriMOP"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vZvb8nsWhOKi"
      },
      "outputs": [],
      "source": [
        "from mlxtend.data import loadlocal_mnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RpkF6Rfihm7p"
      },
      "outputs": [],
      "source": [
        "training_images_filepath = '/content/train-images.idx3-ubyte'\n",
        "training_labels_filepath = '/content/train-labels.idx1-ubyte'\n",
        "test_images_filepath = '/content/t10k-images.idx3-ubyte'\n",
        "test_labels_filepath = '/content/t10k-labels.idx1-ubyte'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fi8o-atVixso"
      },
      "outputs": [],
      "source": [
        "X_train, y_train = loadlocal_mnist( training_images_filepath, training_labels_filepath)\n",
        "X_test, y_test = loadlocal_mnist(test_images_filepath, test_labels_filepath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5lT2rBoi5l8"
      },
      "outputs": [],
      "source": [
        "X_train = X_train.reshape(60000,1, 28, 28).astype(np.float32)\n",
        "X_test = X_test.reshape(10000,1, 28, 28).astype(np.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9z0tQRleZzp-"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5wcX1gs5jjzm"
      },
      "outputs": [],
      "source": [
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KymhEcIu33_p",
        "outputId": "6ecdd8ea-af65-4f92-ac25-b3e08d32666d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "255.0"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "np.max(X_train[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fr7F_QMIx_Up"
      },
      "outputs": [],
      "source": [
        "modelo1 = Net(10,0.0005)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usp9w6BFjYL1",
        "outputId": "de826fb3-9a57-41b7-b487-1398ea2754b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== EPOCH ===== 0\n",
            "Acertados de 100: 5\n",
            "Acertados de 100: 9\n",
            "Acertados de 100: 8\n",
            "Acertados de 100: 7\n",
            "Acertados de 100: 9\n",
            "Acertados de 100: 12\n",
            "Acertados de 100: 10\n",
            "Acertados de 100: 8\n",
            "Acertados de 100: 13\n",
            "Acertados de 100: 11\n",
            "Acertados de 100: 11\n",
            "Acertados de 100: 12\n",
            "Acertados de 100: 12\n",
            "Acertados de 100: 11\n",
            "Acertados de 100: 13\n",
            "Acertados de 100: 17\n",
            "Acertados de 100: 23\n",
            "Acertados de 100: 25\n",
            "Acertados de 100: 11\n",
            "Acertados de 100: 14\n",
            "Acertados de 100: 13\n",
            "Acertados de 100: 16\n",
            "Acertados de 100: 15\n",
            "Acertados de 100: 11\n",
            "Acertados de 100: 17\n",
            "Acertados de 100: 9\n",
            "Acertados de 100: 17\n",
            "Acertados de 100: 16\n",
            "Acertados de 100: 14\n",
            "Acertados de 100: 14\n",
            "Acertados de 100: 20\n",
            "Acertados de 100: 19\n",
            "Acertados de 100: 12\n",
            "Acertados de 100: 21\n",
            "Acertados de 100: 20\n",
            "Acertados de 100: 24\n",
            "Acertados de 100: 27\n",
            "Acertados de 100: 23\n",
            "Acertados de 100: 29\n",
            "Acertados de 100: 37\n",
            "Acertados de 100: 35\n",
            "Acertados de 100: 43\n",
            "Acertados de 100: 36\n",
            "Acertados de 100: 36\n",
            "Acertados de 100: 36\n",
            "Acertados de 100: 42\n",
            "Acertados de 100: 37\n",
            "Acertados de 100: 40\n",
            "Acertados de 100: 46\n",
            "Acertados de 100: 47\n",
            "Acertados de 100: 44\n",
            "Acertados de 100: 47\n",
            "Acertados de 100: 47\n",
            "Acertados de 100: 57\n",
            "Acertados de 100: 45\n",
            "Acertados de 100: 47\n",
            "Acertados de 100: 56\n",
            "Acertados de 100: 42\n",
            "Acertados de 100: 52\n",
            "Acertados de 100: 64\n",
            "===== EPOCH ===== 1\n",
            "Acertados de 100: 52\n",
            "Acertados de 100: 54\n",
            "Acertados de 100: 51\n",
            "Acertados de 100: 62\n",
            "Acertados de 100: 61\n",
            "Acertados de 100: 68\n",
            "Acertados de 100: 56\n",
            "Acertados de 100: 51\n",
            "Acertados de 100: 57\n",
            "Acertados de 100: 61\n",
            "Acertados de 100: 60\n",
            "Acertados de 100: 64\n",
            "Acertados de 100: 56\n",
            "Acertados de 100: 55\n",
            "Acertados de 100: 55\n",
            "Acertados de 100: 63\n",
            "Acertados de 100: 64\n",
            "Acertados de 100: 62\n",
            "Acertados de 100: 55\n",
            "Acertados de 100: 57\n",
            "Acertados de 100: 65\n",
            "Acertados de 100: 54\n",
            "Acertados de 100: 50\n",
            "Acertados de 100: 52\n",
            "Acertados de 100: 55\n",
            "Acertados de 100: 60\n",
            "Acertados de 100: 66\n",
            "Acertados de 100: 60\n",
            "Acertados de 100: 57\n",
            "Acertados de 100: 69\n",
            "Acertados de 100: 59\n",
            "Acertados de 100: 54\n",
            "Acertados de 100: 66\n",
            "Acertados de 100: 62\n",
            "Acertados de 100: 61\n",
            "Acertados de 100: 69\n",
            "Acertados de 100: 63\n",
            "Acertados de 100: 65\n",
            "Acertados de 100: 62\n",
            "Acertados de 100: 67\n",
            "Acertados de 100: 67\n",
            "Acertados de 100: 61\n",
            "Acertados de 100: 69\n",
            "Acertados de 100: 65\n",
            "Acertados de 100: 72\n",
            "Acertados de 100: 64\n",
            "Acertados de 100: 65\n",
            "Acertados de 100: 70\n",
            "Acertados de 100: 68\n",
            "Acertados de 100: 63\n",
            "Acertados de 100: 64\n",
            "Acertados de 100: 62\n",
            "Acertados de 100: 71\n",
            "Acertados de 100: 70\n",
            "Acertados de 100: 66\n",
            "Acertados de 100: 59\n",
            "Acertados de 100: 61\n",
            "Acertados de 100: 67\n",
            "Acertados de 100: 65\n",
            "Acertados de 100: 71\n",
            "===== EPOCH ===== 2\n",
            "Acertados de 100: 63\n",
            "Acertados de 100: 68\n",
            "Acertados de 100: 70\n",
            "Acertados de 100: 65\n",
            "Acertados de 100: 63\n",
            "Acertados de 100: 63\n",
            "Acertados de 100: 59\n",
            "Acertados de 100: 68\n",
            "Acertados de 100: 58\n",
            "Acertados de 100: 58\n",
            "Acertados de 100: 65\n",
            "Acertados de 100: 66\n",
            "Acertados de 100: 74\n",
            "Acertados de 100: 60\n",
            "Acertados de 100: 67\n",
            "Acertados de 100: 64\n",
            "Acertados de 100: 62\n",
            "Acertados de 100: 73\n",
            "Acertados de 100: 66\n",
            "Acertados de 100: 69\n",
            "Acertados de 100: 70\n",
            "Acertados de 100: 74\n",
            "Acertados de 100: 63\n",
            "Acertados de 100: 78\n",
            "Acertados de 100: 69\n",
            "Acertados de 100: 67\n",
            "Acertados de 100: 66\n",
            "Acertados de 100: 68\n",
            "Acertados de 100: 53\n",
            "Acertados de 100: 70\n",
            "Acertados de 100: 67\n",
            "Acertados de 100: 67\n",
            "Acertados de 100: 75\n",
            "Acertados de 100: 68\n",
            "Acertados de 100: 65\n",
            "Acertados de 100: 63\n",
            "Acertados de 100: 70\n",
            "Acertados de 100: 65\n",
            "Acertados de 100: 74\n",
            "Acertados de 100: 66\n",
            "Acertados de 100: 76\n",
            "Acertados de 100: 57\n",
            "Acertados de 100: 61\n",
            "Acertados de 100: 68\n",
            "Acertados de 100: 57\n",
            "Acertados de 100: 62\n",
            "Acertados de 100: 66\n",
            "Acertados de 100: 73\n",
            "Acertados de 100: 63\n",
            "Acertados de 100: 61\n",
            "Acertados de 100: 65\n",
            "Acertados de 100: 65\n",
            "Acertados de 100: 73\n"
          ]
        }
      ],
      "source": [
        "epochs = 10\n",
        "idn = 0\n",
        "for i in range(0,epochs,1):\n",
        "  print(f'===== EPOCH ===== {i}')\n",
        "  for x,y in zip(X_train,y_train):\n",
        "    idn += 1\n",
        "\n",
        "    modelo1.backward((x/255)-0.5,y)\n",
        "\n",
        "    if idn%1000 == 0:\n",
        "      idx_v = set()\n",
        "      c = 0\n",
        "      for _ in range(100):\n",
        "        while True:\n",
        "          T =np.random.randint(0,len(X_test))\n",
        "          if T not in idx_v:\n",
        "            break\n",
        "        idx_v.add(T)\n",
        "        probs = modelo1.forward((X_test[T]/255) -0.5)\n",
        "        probs = [prob for prob in probs[0]]\n",
        "        if y_test[T] == probs.index(max(probs)):\n",
        "          c += 1\n",
        "      print(f'Acertados de 100: {c}')\n",
        "  idn = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test each example by hand**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_050XGeRc4O2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UKE4Dqw8t2h9"
      },
      "outputs": [],
      "source": [
        "T =np.random.randint(0,len(X_train))\n",
        "cv2_imshow(X_train[T][0])\n",
        "x = modelo1.forward(X_train[T])\n",
        "print(np.max(x[0]))\n",
        "prob = []\n",
        "print(x.shape)\n",
        "for i in x[0]:\n",
        "  prob.append(i)\n",
        "print(y_train[T],prob)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qBVP9bNe__BT"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}